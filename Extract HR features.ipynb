{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aedab3d",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee42b88a",
   "metadata": {},
   "source": [
    "Save the file path and the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c99f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "fakevideoFilename=[]\n",
    "fakefilename=[] # video file path\n",
    "\n",
    "basepath='./Dataset/' # you need to edit the path\n",
    "with os.scandir(basepath) as entries:\n",
    "    for entry in entries:\n",
    "        # print('entry: ', entry)\n",
    "        if entry.is_dir():\n",
    "            nextpath=basepath+entry.name+'/' \n",
    "            if(entry.name!=\".ipynb_checkpoints\"):  #and entry.name!=\".ipynb_checkpoints\"\n",
    "                with os.scandir(nextpath) as dirs:\n",
    "                    for directory in dirs:\n",
    "                        # print('directory: ', directory)\n",
    "                        if directory.is_dir() and directory.name!=\".ipynb_checkpoints\": #and directory.name!=\".ipynb_checkpoints\"\n",
    "                            finalpath=nextpath+directory.name+'/'\n",
    "                            with os.scandir(finalpath) as filenames:\n",
    "                                for filename in filenames:\n",
    "                                    # print('filename: ', filename)\n",
    "                                    if filename.is_dir() and filename.name!=\".ipynb_checkpoints\":\n",
    "                                        ffinalpath=finalpath+filename.name+'/'\n",
    "                                        with os.scandir(ffinalpath) as ffilenames:\n",
    "                                            for ffilename in ffilenames:\n",
    "                                                if ffilename.is_file() and ffilename.name!=\"croppedFaces.npz\":\n",
    "                                                    real_final_path=ffinalpath+ffilename.name                                                                       \n",
    "                                                    fakefilename.append(filename.name+\"_\"+entry.name+\"_\"+directory.name+\".xlsx\")\n",
    "                                                    fakevideoFilename.append(real_final_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cf0e15",
   "metadata": {},
   "source": [
    "### Save HR feature in excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db10b5d2",
   "metadata": {},
   "source": [
    "Define functions that make excell files for HR features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31427f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "\n",
    "def make_excel(filepath,filename,bpmES,method,timestamp):\n",
    "    if timestamp==1: \n",
    "        ch=1\n",
    "    elif timestamp==0.1: \n",
    "        ch=10\n",
    "    else: \n",
    "        ch=5\n",
    "        \n",
    "    wb=Workbook()\n",
    "\n",
    "    for sheet in wb.sheetnames:\n",
    "        wb.remove(wb[sheet])\n",
    "\n",
    "    ws=wb.create_sheet(filename)\n",
    "    position = 0\n",
    "    column=1\n",
    "\n",
    "    for bpm in bpmES:\n",
    "        row=1\n",
    "        ws.cell(row=row,column=column, value=position)\n",
    "        row+=1\n",
    "        # a: Standard deviation of all HRs\n",
    "        var_a = np.std(bpm)\n",
    "\n",
    "        # b: The square root of the mean of the sum of the squares of differences between adjacent HRs\n",
    "        b_list = []\n",
    "        for i in range(0, len(bpm[0])-1):\n",
    "            b_list.append(abs(bpm[0][i] - bpm[0][i+1])** 2)\n",
    "        var_b = np.mean(b_list)\n",
    "        var_b = np.sqrt(var_b)\n",
    "              \n",
    "        # c. Standard deviation of differences between adjacent NN intervals\n",
    "        c_list = []\n",
    "        for i in range(0, len(bpm[0])-1):\n",
    "            c_list.append(abs(bpm[0][i] - bpm[0][i+1]))\n",
    "        var_c=np.std(c_list)          \n",
    "        \n",
    "        position = position + 1\n",
    "\n",
    "        #csv write\n",
    "        ws.cell(row=row,column=column, value=var_a)\n",
    "        row+=1\n",
    "        ws.cell(row=row,column=column, value=var_b)\n",
    "        row+=1\n",
    "        ws.cell(row=row,column=column, value=var_c)\n",
    "        column+=1\n",
    "\n",
    "\n",
    "    # save\n",
    "    wb.save(filepath+str(timestamp)+'_'+method+'_'+filename)\n",
    "    wb.close()\n",
    "\n",
    "    print('-> '+filename+'save done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b54faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "\n",
    "def make_avg_excel(filepath,filename,bpmEs,method, timestamp):\n",
    "    if timestamp==1: \n",
    "        ch=1\n",
    "    elif timestamp==0.1: \n",
    "        ch=10\n",
    "    else: \n",
    "        ch=5\n",
    "        \n",
    "    wb=Workbook()\n",
    "\n",
    "    for sheet in wb.sheetnames:\n",
    "        wb.remove(wb[sheet])\n",
    "\n",
    "    ws=wb.create_sheet(filename)\n",
    "    position = 0\n",
    "    column=1\n",
    "\n",
    "    #avgbpm\n",
    "    avgbpm = [0 for i in range(len(bpmES[0][0]))]\n",
    "    a = 0\n",
    "    for bpm in bpmES[:9]:\n",
    "        a = a + 1\n",
    "        for i in range(len(bpm[0])):\n",
    "            avgbpm[i] = avgbpm[i] + bpm[0][i]\n",
    "    for i in range(len(bpm[0])):\n",
    "        avgbpm[i] = avgbpm[i]/9\n",
    "\n",
    "    row=1\n",
    "    ws.cell(row=row,column=column, value=position)\n",
    "    count = 0\n",
    "    row+=1\n",
    "    # a: Standard deviation of all BPMs\n",
    "    var_a = np.std(avgbpm)\n",
    "\n",
    "    # b: The square root of the mean of the sum of the squares of differences between adjacent BPMs\n",
    "    b_list = []\n",
    "    for i in range(0, len(avgbpm)-1):\n",
    "        b_list.append(abs(avgbpm[i] - avgbpm[i+1])** 2)\n",
    "    var_b = np.mean(b_list)\n",
    "    var_b = np.sqrt(var_b)\n",
    "        \n",
    "        \n",
    "    # c. Standard deviation of differences between adjacent NN intervals\n",
    "    c_list = []\n",
    "    for i in range(0, len(avgbpm)-1):\n",
    "        c_list.append(abs(avgbpm[i] - avgbpm[i+1]))\n",
    "    var_c=np.std(c_list)\n",
    "        \n",
    "    position = position + 1\n",
    "\n",
    "    #csv write\n",
    "    ws.cell(row=row,column=column, value=var_a)\n",
    "    row+=1\n",
    "    ws.cell(row=row,column=column, value=var_b)\n",
    "    row+=1\n",
    "    ws.cell(row=row,column=column, value=var_c)\n",
    "    column+=1\n",
    "\n",
    "    # save\n",
    "    wb.save(filepath+str(timestamp)+'_'+method+'_'+'avg_'+filename)\n",
    "    wb.close()\n",
    "\n",
    "    print('-> '+filename+\"_avg\"+' save done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c48d2c",
   "metadata": {},
   "source": [
    "Define labels for face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02051751",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_area = {'./Dataset/real/ff/098/098.mp4':[[5 , 2 , 95 , 138]],\n",
    "           './Dataset/real/ff/107/107.mp4':[[0 , 8 , 85 , 110]],\n",
    "            './Dataset/real/ff/109/109.mp4':[[0 , 3 , 94 , 128]],\n",
    "            './Dataset/real/ff/113/113.mp4':[[2 , 50 , 161 , 172]],\n",
    "            './Dataset/real/ff/119/119.mp4':[[0, 2, 90, 127]],\n",
    "            './Dataset/real/ff/122/122.mp4':[[0, 50, 275, 370]],\n",
    "            './Dataset/real/ff/123/123.mp4':[[0, 17, 96, 110]],\n",
    "            './Dataset/real/ff/134/134.mp4':[[2, 40, 160, 180]],\n",
    "            './Dataset/real/ff/141/141.mp4':[[0, 3, 95, 128]],\n",
    "            './Dataset/real/ff/144/144.mp4':[[8, 0, 280, 400]],\n",
    "            './Dataset/real/ff/147/147.mp4':[[3, 13, 131, 170]],\n",
    "            './Dataset/real/ff/161/161.mp4':[[3, 13, 93, 121]],\n",
    "            './Dataset/real/ff/168/168.mp4':[[3, 13, 84, 113]],\n",
    "            './Dataset/real/ff/182/182.mp4':[[3, 3, 144, 203]],\n",
    "            './Dataset/real/ff/189/189.mp4':[[0, 3, 100, 133]],\n",
    "            './Dataset/real/ff/192/192.mp4':[[18, 3, 160, 244]],\n",
    "            './Dataset/real/ff/194/194.mp4':[[0, 23, 102, 112]],\n",
    "            './Dataset/real/ff/200/200.mp4':[[0, 13, 96, 111]],\n",
    "            './Dataset/real/ff/222/222.mp4':[[2, 13, 98, 120]],\n",
    "            './Dataset/real/ff/226/226.mp4':[[2, 0, 180, 253]],\n",
    "            './Dataset/real/ff/235/235.mp4':[[0, 3, 104, 143]],\n",
    "            './Dataset/real/ff/242/242.mp4':[[2, 10, 113, 175]],\n",
    "            './Dataset/real/ff/278/278.mp4':[[1, 3, 68, 98]],\n",
    "            './Dataset/real/ff/293/293.mp4':[[1, 7, 106, 141]],\n",
    "            './Dataset/real/ff/296/296.mp4':[[1, 7, 106, 137]],\n",
    "            './Dataset/real/ff/303/303.mp4':[[1, 8, 100, 135]],\n",
    "            './Dataset/real/ff/306/306.mp4':[[1, 8, 78, 105]],\n",
    "            './Dataset/real/ff/309/309.mp4':[[9, 10, 85, 121]],\n",
    "            './Dataset/real/ff/316/316.mp4':[[0, 8, 95, 116]],\n",
    "            './Dataset/real/ff/327/327.mp4':[[1, 2, 74, 97]],\n",
    "            './Dataset/real/ff/329/329.mp4':[[1, 6, 84, 107]],\n",
    "            './Dataset/real/ff/337/337.mp4':[[1, 7, 69, 89]],\n",
    "            './Dataset/real/ff/349/349.mp4':[[9, 7, 87, 126]],\n",
    "            './Dataset/real/ff/350/350.mp4':[[6, 7, 102, 138]],\n",
    "            './Dataset/real/ff/358/358.mp4':[[0, 0, 115, 168]],\n",
    "            './Dataset/real/ff/366/366.mp4':[[0, 10, 76, 97]],\n",
    "            './Dataset/real/ff/369/369.mp4':[[0, 0, 98, 135]],\n",
    "            './Dataset/real/ff/380/380.mp4':[[0, 0, 119, 165]],\n",
    "            './Dataset/real/ff/382/382.mp4':[[0, 0, 63, 88]],\n",
    "            './Dataset/real/ff/398/398.mp4':[[0, 11, 119, 152]],\n",
    "            './Dataset/real/ff/399/399.mp4':[[0, 15, 250, 355]],\n",
    "            './Dataset/real/ff/408/408.mp4':[[0, 15, 99, 120]],\n",
    "            './Dataset/real/ff/409/409.mp4':[[0, 2, 59, 85]],\n",
    "            './Dataset/real/ff/418/418.mp4':[[0, 20, 389, 565]],\n",
    "            './Dataset/real/ff/424/424.mp4':[[0, 0, 97, 137]],\n",
    "            './Dataset/real/ff/436/436.mp4':[[0, 0, 117, 167]],\n",
    "            './Dataset/real/ff/449/449.mp4':[[15, 20, 188, 241]],\n",
    "            './Dataset/real/ff/451/451.mp4':[[0, 0, 178, 251]],\n",
    "            './Dataset/real/ff/457/457.mp4':[[0, 0, 109, 168]],\n",
    "            './Dataset/real/ff/473/473.mp4':[[0, 0, 80, 108]],\n",
    "            './Dataset/real/ff/488/488.mp4':[[0, 15, 250, 266]],\n",
    "            './Dataset/real/ff/491/491.mp4':[[36, 4, 110, 212]],\n",
    "            './Dataset/real/ff/558/558.mp4':[[0, 4, 170, 239]],\n",
    "            './Dataset/real/ff/618/618.mp4':[[0, 4, 185, 249]],\n",
    "            './Dataset/real/ff/619/619.mp4':[[0, 4, 185, 249]],\n",
    "            './Dataset/real/ff/620/620.mp4':[[0, 4, 215, 281]],\n",
    "            './Dataset/real/ff/629/629.mp4':[[0, 4, 155, 221]],\n",
    "            './Dataset/real/ff/699/699.mp4':[[0, 4, 91, 121]],\n",
    "            './Dataset/real/ff/705/705.mp4':[[0, 15, 122, 153]],\n",
    "            './Dataset/real/ff/707/707.mp4':[[0, 15, 112, 138]],\n",
    "            './Dataset/real/ff/719/719.mp4':[[0, 7, 102, 137]],\n",
    "            './Dataset/real/ff/761/761.mp4':[[0, 7, 82, 106]],\n",
    "            './Dataset/fake/Deepfakes/107_109/107_109.mp4':[[1 , 10 , 82 , 110]],\n",
    "            './Dataset/fake/Deepfakes/109_107/109_107.mp4':[[1 , 8 , 93 , 120]],\n",
    "            './Dataset/fake/Deepfakes/113_983/113_983.mp4':[[1 , 12 , 150 , 200]],\n",
    "            './Dataset/fake/Deepfakes/119_123/119_123.mp4':[[1 , 6 , 90 , 122]],\n",
    "            './Dataset/fake/Deepfakes/122_144/122_144.mp4':[[1 , 20 , 270 , 380]],\n",
    "            './Dataset/fake/Deepfakes/123_119/123_119.mp4':[[1 , 5 , 95 , 125]],\n",
    "            './Dataset/fake/Deepfakes/134_192/134_192.mp4':[[1 , 12 , 155 , 190]],\n",
    "            './Dataset/fake/Deepfakes/141_161/141_161.mp4':[[1 , 6 , 95 , 130]],\n",
    "            './Dataset/fake/Deepfakes/144_122/144_122.mp4':[[1 , 6 , 260 , 355]],\n",
    "            './Dataset/fake/Deepfakes/147_055/147_055.mp4':[[1 , 8 , 130 , 175]],\n",
    "            './Dataset/fake/Deepfakes/161_141/161_141.mp4':[[1 , 8 , 97 , 125]],\n",
    "            './Dataset/fake/Deepfakes/168_222/168_222.mp4':[[5 , 12 , 89 , 115]],\n",
    "            './Dataset/fake/Deepfakes/182_242/182_242.mp4':[[10 , 6 , 125 , 200]],\n",
    "            './Dataset/fake/Deepfakes/189_200/189_200.mp4':[[1 , 4 , 95 , 127]],\n",
    "            './Dataset/fake/Deepfakes/192_134/192_134.mp4':[[13 , 11 , 170 , 240]],\n",
    "            './Dataset/fake/Deepfakes/194_235/194_235.mp4':[[2 , 20 , 95 , 110]],\n",
    "            './Dataset/fake/Deepfakes/200_189/200_189.mp4':[[2 , 15 , 93 , 110]],\n",
    "            './Dataset/fake/FaceShifter/222_168/222_168.mp4':[[5 , 10 , 95 , 122]],\n",
    "            './Dataset/fake/FaceShifter/226_491/226_491.mp4':[[2 , 3 , 185 , 252]],\n",
    "            './Dataset/fake/FaceShifter/235_194/235_194.mp4':[[2 , 4 , 95 , 135]],\n",
    "            './Dataset/fake/FaceShifter/242_182/242_182.mp4':[[4 , 10 , 110 , 175]],\n",
    "            './Dataset/fake/FaceShifter/278_306/278_306.mp4':[[2 , 4 , 67 , 95]],\n",
    "            './Dataset/fake/FaceShifter/293_296/293_296.mp4':[[2 , 3 , 106 , 142]],\n",
    "            './Dataset/fake/Face2Face/296_293/296_293.mp4':[[2 , 6 , 102 , 143]],\n",
    "            './Dataset/fake/Face2Face/303_309/303_309.mp4':[[2 , 10 , 95 , 135]],\n",
    "            './Dataset/fake/Face2Face/306_278/306_278.mp4':[[2 , 10 , 72 , 97]],\n",
    "            './Dataset/fake/Face2Face/309_303/309_303.mp4':[[4 , 12 , 90 , 125]],\n",
    "            './Dataset/fake/Face2Face/316_369/316_369.mp4':[[2 , 6 , 92 , 122]],\n",
    "            './Dataset/fake/Face2Face/327_329/327_329.mp4':[[2 , 6 , 72 , 95]],\n",
    "            './Dataset/fake/Face2Face/329_327/329_327.mp4':[[2 , 8 , 83 , 107]],\n",
    "            './Dataset/fake/Face2Face/337_522/337_522.mp4':[[1 , 6 , 68 , 87]],\n",
    "            './Dataset/fake/Face2Face/349_350/349_350.mp4':[[10 , 7 , 90 , 125]],\n",
    "            './Dataset/fake/Face2Face/350_349/350_349.mp4':[[2 , 8 , 105 , 139]],\n",
    "            './Dataset/fake/Face2Face/358_380/358_380.mp4':[[2 , 3 , 111 , 169]],\n",
    "            './Dataset/fake/Face2Face/366_473/366_473.mp4':[[2 , 5 , 73 , 94]],\n",
    "            './Dataset/fake/Face2Face/369_316/369_316.mp4':[[2 , 5 , 97 , 129]],\n",
    "            './Dataset/fake/Face2Face/380_358/380_358.mp4':[[3 , 5 , 115 , 155]],\n",
    "            './Dataset/fake/Face2Face/382_409/382_409.mp4':[[3 , 2 , 57 , 85]],\n",
    "            './Dataset/fake/Face2Face/398_457/398_457.mp4':[[12 , 8 , 102 , 150]],\n",
    "            './Dataset/fake/Face2Face/399_488/399_488.mp4':[[9 , 6 , 235 , 345]],\n",
    "            './Dataset/fake/Face2Face/408_424/408_424.mp4':[[2 , 8 , 96 , 120]],\n",
    "            './Dataset/fake/FaceShifter/409_382/409_382.mp4':[[2 , 10 , 58 , 81]],\n",
    "            './Dataset/fake/FaceShifter/418_507/418_507.mp4':[[2 , 25 , 365 , 527]],\n",
    "            './Dataset/fake/FaceShifter/424_408/424_408.mp4':[[2 , 3 , 99 , 145]],\n",
    "            './Dataset/fake/FaceShifter/436_526/436_526.mp4':[[2 , 3 , 120 , 159]],\n",
    "            './Dataset/fake/FaceShifter/449_451/449_451.mp4':[[7 , 40 , 182 , 210]],\n",
    "            './Dataset/fake/FaceShifter/451_449/451_449.mp4':[[5 , 3 , 180 , 250]],\n",
    "            './Dataset/fake/FaceShifter/457_398/457_398.mp4':[[5 , 3 , 107 , 160]],\n",
    "            './Dataset/fake/FaceShifter/473_366/473_366.mp4':[[2 , 3 , 75 , 105]],\n",
    "            './Dataset/fake/FaceShifter/488_399/488_399.mp4':[[2 , 11 , 210 , 280]],\n",
    "            './Dataset/fake/FaceShifter/491_226/491_226.mp4':[[30 , 3 , 112 , 200]],\n",
    "            './Dataset/fake/FaceShifter/507_418/507_418.mp4':[[2 , 4 , 523 , 740]],\n",
    "            './Dataset/fake/FaceShifter/522_337/522_337.mp4':[[1 , 4 , 56 , 82]],\n",
    "            './Dataset/fake/FaceShifter/526_436/526_436.mp4':[[1 , 6 , 136 , 190]],\n",
    "            './Dataset/fake/FaceShifter/536_540/536_540.mp4':[[1 , 12 , 175 , 242]],\n",
    "            './Dataset/fake/FaceShifter/540_536/540_536.mp4':[[1 , 19 , 160 , 230]],\n",
    "            './Dataset/fake/FaceShifter/558_583/558_583.mp4':[[1 , 19 , 160 , 220]],\n",
    "            './Dataset/fake/FaceShifter/583_558/583_558.mp4':[[1 , 25 , 160 , 210]],\n",
    "            './Dataset/fake/FaceShifter/595_597/595_597.mp4':[[1 , 8 , 104 , 140]],\n",
    "            './Dataset/fake/FaceShifter/597_595/597_595.mp4':[[3 , 8 , 104 , 140]],\n",
    "            './Dataset/fake/FaceShifter/618_629/618_629.mp4':[[3 , 12 , 175 , 225]],\n",
    "            './Dataset/fake/FaceShifter/619_620/619_620.mp4':[[3 , 4 , 185 , 255]],\n",
    "            './Dataset/real/ff/001/001.mp4':[[3 , 15 , 140 , 169]],\n",
    "            './Dataset/real/ff/055/055.mp4':[[15 , 6 , 125 , 185]],\n",
    "            './Dataset/real/ff/065/065.mp4':[[2 , 6 , 200 , 270]],\n",
    "            './Dataset/real/ff/074/074.mp4':[[10 , 10 , 209 , 289]],\n",
    "            './Dataset/real/ff/089/089.mp4':[[2 , 15 , 196 , 260]],\n",
    "            './Dataset/real/ff/092/092.mp4':[[2 , 13 , 90 , 108]],\n",
    "            './Dataset/fake/FaceSwap/872_873/872_873.mp4':[[0 , 0 , 115 , 157]],\n",
    "            './Dataset/fake/FaceSwap/873_872/873_872.mp4':[[0 , 0 , 120 , 170]],\n",
    "            './Dataset/fake/FaceSwap/875_979/875_979.mp4':[[0 , 0 , 180 , 265]],\n",
    "            './Dataset/fake/FaceSwap/897_969/897_969.mp4':[[0 , 10 , 58 , 70]],\n",
    "            './Dataset/fake/FaceSwap/899_914/899_914.mp4':[[0 , 10 , 120 , 140]],\n",
    "            './Dataset/fake/FaceSwap/903_792/903_792.mp4':[[5 , 10 , 140 , 185]],\n",
    "            './Dataset/fake/FaceSwap/914_899/914_899.mp4':[[0 , 10 , 125 , 170]],\n",
    "            './Dataset/fake/FaceSwap/917_924/917_924.mp4':[[5 , 5 , 95 , 130]],\n",
    "            './Dataset/fake/FaceSwap/924_917/924_917.mp4':[[0 , 5 , 97 , 132]],\n",
    "            './Dataset/fake/FaceSwap/956_958/956_958.mp4':[[0 , 0 , 87 , 130]],\n",
    "            './Dataset/fake/FaceSwap/958_956/958_956.mp4':[[0 , 0 , 93 , 123]],\n",
    "            './Dataset/fake/FaceSwap/967_984/967_984.mp4':[[0 , 0 , 185 , 250]],\n",
    "            './Dataset/fake/FaceSwap/969_897/969_897.mp4':[[0 , 0 , 57 , 80]],\n",
    "            './Dataset/fake/FaceSwap/979_875/979_875.mp4':[[0 , 10 , 173 , 255]],\n",
    "            './Dataset/fake/FaceSwap/983_113/983_113.mp4':[[0 , 10 , 125 , 165]],\n",
    "            './Dataset/fake/FaceSwap/984_967/984_967.mp4':[[5 , 10 , 185 , 245]],\n",
    "            './Dataset/fake/NeuralTextures/001_870/001_870.mp4':[[0 , 10 , 133 , 167]],\n",
    "            './Dataset/fake/NeuralTextures/055_147/055_147.mp4':[[3 , 0 , 133 , 189]],\n",
    "            './Dataset/fake/NeuralTextures/065_089/065_089.mp4':[[0 , 0 , 200 , 280]],\n",
    "            './Dataset/fake/NeuralTextures/074_825/074_825.mp4':[[5 , 0 , 210 , 300]],\n",
    "            './Dataset/fake/NeuralTextures/089_065/089_065.mp4':[[0 , 25 , 200 , 255]],\n",
    "            './Dataset/fake/NeuralTextures/092_098/092_098.mp4':[[0 , 10 , 100 , 108]],\n",
    "            './Dataset/fake/NeuralTextures/098_092/098_092.mp4':[[0 , 5 , 103 , 137]],\n",
    "            './Dataset/fake/NeuralTextures/620_619/620_619.mp4':[[0 , 0 , 215 , 305]],\n",
    "            './Dataset/fake/NeuralTextures/629_618/629_618.mp4':[[0 , 0 , 155 , 230]],\n",
    "            './Dataset/fake/NeuralTextures/705_707/705_707.mp4':[[0 , 25 , 125 , 155]],\n",
    "            './Dataset/fake/NeuralTextures/707_705/707_705.mp4':[[0 , 10 , 115 , 138]],\n",
    "            './Dataset/fake/NeuralTextures/792_903/792_903.mp4':[[0 , 0 , 132 , 205]],\n",
    "            './Dataset/fake/NeuralTextures/800_840/800_840.mp4':[[0 , 0 , 110 , 150]],\n",
    "            './Dataset/fake/NeuralTextures/825_074/825_074.mp4':[[0 , 5 , 235 , 335]],\n",
    "            './Dataset/fake/NeuralTextures/840_800/840_800.mp4':[[0 , 5 , 120 , 153]],\n",
    "            './Dataset/fake/NeuralTextures/870_001/870_001.mp4':[[0 , 5 , 167 , 183]],\n",
    "            './Dataset/real/ff/792/792.mp4':[[0 , 0 , 140 , 210]],\n",
    "            './Dataset/real/ff/800/800.mp4':[[0 , 0 , 103 , 157]],\n",
    "            './Dataset/real/ff/825/825.mp4':[[0 , 5 , 230 , 340]],\n",
    "            './Dataset/real/ff/840/840.mp4':[[0 , 20 , 115 , 135]],\n",
    "            './Dataset/real/ff/870/870.mp4':[[0 , 10 , 160 , 180]],\n",
    "            './Dataset/real/ff/872/872.mp4':[[0 , 10 , 115 , 145]],\n",
    "            './Dataset/real/ff/873/873.mp4':[[0 , 10 , 125 , 165]],\n",
    "            './Dataset/real/ff/875/875.mp4':[[0 , 20 , 175 , 245]],\n",
    "            './Dataset/real/ff/897/897.mp4':[[0 , 5 , 57 , 72]],\n",
    "            './Dataset/real/ff/899/899.mp4':[[0 , 20 , 120 , 135]],\n",
    "            './Dataset/real/ff/903/903.mp4':[[0 , 20 , 140 , 175]],\n",
    "            './Dataset/real/ff/914/914.mp4':[[0 , 0 , 120 , 165]],\n",
    "            './Dataset/real/ff/917/917.mp4':[[0 , 0 , 93 , 130]],\n",
    "            './Dataset/real/ff/924/924.mp4':[[0 , 0 , 99 , 137]],\n",
    "            './Dataset/real/ff/956/956.mp4':[[0 , 0 , 90 , 135]],\n",
    "            './Dataset/real/ff/958/958.mp4':[[0 , 0 , 99 , 121]],\n",
    "            './Dataset/real/ff/967/967.mp4':[[0 , 0 , 185 , 255]],\n",
    "            './Dataset/real/ff/969/969.mp4':[[0 , 5 , 57 , 80]],\n",
    "            './Dataset/real/ff/979/979.mp4':[[0 , 10 , 175 , 235]],\n",
    "            './Dataset/real/ff/983/983.mp4':[[0 , 15 , 130 , 163]],\n",
    "            './Dataset/real/ff/984/984.mp4':[[5 , 10 , 180 , 240]]\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6dc7fa",
   "metadata": {},
   "source": [
    "Extract HR values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637b98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dic = dict()\n",
    "import tensorflow as tf\n",
    "from pyVHR.signals.video import Video\n",
    "from pyVHR.analysis.testsuite import TestSuite, TestResult\n",
    "\n",
    "from pyVHR.methods.pos import POS\n",
    "from pyVHR.methods.chrom import CHROM\n",
    "from pyVHR.methods.green import GREEN\n",
    "from pyVHR.methods.ica import ICA\n",
    "from pyVHR.methods.lgi import LGI\n",
    "from pyVHR.methods.pbv import PBV\n",
    "from pyVHR.methods.pca import PCA\n",
    "from pyVHR.methods.ssr import SSR\n",
    "import numpy as np\n",
    "for index_v in range(len(fakevideoFilename)):\n",
    "    videoFilename =fakevideoFilename[index_v]\n",
    "    video = Video(videoFilename)\n",
    "    # -- extract faces\n",
    "    try:\n",
    "        video.getCroppedFaces(detector='mtcnn', extractor='skvideo')\n",
    "        #video.printVideoInfo()\n",
    "        #video.showVideo()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"-----------------Error-------------------\")\n",
    "        print(videoFilename+\" | face not Detected!\")\n",
    "        print(\"-----------------------------------------\")\n",
    "        notsaved.append(videoFilename)\n",
    "    video.setMask(typeROI='rect', rectCoords=vid_area[fakevideoFilename[index_v]])\n",
    "    video.showVideo()\n",
    "    # -- define ROIs: free rectangular regions\n",
    "    y=video.cropSize[0]\n",
    "    x=video.cropSize[1]\n",
    "    areas=[]\n",
    "    left_x = vid_area[fakevideoFilename[index_v]][0][0] # x for left top\n",
    "    left_y = vid_area[fakevideoFilename[index_v]][0][1] # y for left top\n",
    "    x = vid_area[fakevideoFilename[index_v]][0][2] # difference of x\n",
    "    y = vid_area[fakevideoFilename[index_v]][0][3] # difference of y\n",
    "    w=x/3\n",
    "    h=y/3\n",
    "    rectCoords=[[left_x,left_y,w,h],[w+left_x,left_y,w,h],[2*w+left_x,left_y,w,h],[left_x,h+left_y,w,h],[w+left_x,h+left_y,w,h],[w*2+left_x,h+left_y,w,h],[left_x,h*2+left_y,w,h],[w+left_x,h*2+left_y,w,h],[2*w+left_x,2*h+left_y,w,h]]\n",
    "    fullface=\"[\"\n",
    "    for i in range(9):\n",
    "        components=','.join(str(e) for e in rectCoords[i])\n",
    "        areas.append(\"[[\"+components+\"]]\")\n",
    "        fullface=fullface+\"[\"+components+\"]\"+ (\",\" if i!=8 else \"]\")\n",
    "    areas.append(fullface)\n",
    "    label_dic[videoFilename] = areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af572c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(label_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a938a4",
   "metadata": {},
   "source": [
    "Save HR features in *Feature* folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fdc0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pyVHR.signals.video import Video\n",
    "from pyVHR.analysis.testsuite import TestSuite, TestResult\n",
    "\n",
    "from pyVHR.methods.pos import POS\n",
    "from pyVHR.methods.chrom import CHROM\n",
    "from pyVHR.methods.green import GREEN\n",
    "from pyVHR.methods.ica import ICA\n",
    "from pyVHR.methods.lgi import LGI\n",
    "from pyVHR.methods.pbv import PBV\n",
    "from pyVHR.methods.pca import PCA\n",
    "from pyVHR.methods.ssr import SSR\n",
    "import numpy as np\n",
    "\n",
    "notsaved=[]\n",
    "method_list=['ICA', 'PCA', 'GREEN', 'CHROM', 'LGI', 'PBV']\n",
    "timestamp=[1, 0.5, 0.1]\n",
    "\n",
    "# path for excel\n",
    "filepath='./Feature/'\n",
    "\n",
    "for method in method_list:\n",
    "    for videoFilename,filename in zip(fakevideoFilename,fakefilename):\n",
    "        for t__ in timestamp:\n",
    "            print(filename)\n",
    "            print(videoFilename)\n",
    "            video = Video(videoFilename)\n",
    "            # -- extract faces\n",
    "            try:\n",
    "                video.getCroppedFaces(detector='mtcnn', extractor='skvideo')\n",
    "                video.printVideoInfo()\n",
    "                video.showVideo()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"-----------------Error-------------------\")\n",
    "                print(videoFilename+\" | face not Detected!\")\n",
    "                print(\"-----------------------------------------\")\n",
    "                notsaved.append(videoFilename)\n",
    "                continue\n",
    "\n",
    "            m=[]\n",
    "            rgbES=[]\n",
    "            bpmES=[]\n",
    "            timesES=[]\n",
    "            n=len(areas)\n",
    "\n",
    "            for i in range(n):\n",
    "                rgbES.append(None)\n",
    "                bpmES.append(None)\n",
    "                timesES.append(None)\n",
    "                params = {\"video\": video, \"verb\":4, \"timeStep\":t__,\"ROImask\":\"rect\",\"rectCoords\":label_dic[videoFilename][i]}\n",
    "\n",
    "                # -- invoke the method\n",
    "                m.append(globals()[method](**params))\n",
    "\n",
    "                # -- invoke the method\n",
    "                bpmES[i], timesES[i] = m[i].runOffline(**params)\n",
    "            make_avg_excel(filepath,filename,bpmES[:9],method, t__)\n",
    "            make_excel(filepath,filename,bpmES,method, t__)\n",
    "            #make_avg_excel(filepath,filename,bpmES[:16],method, t__)\n",
    "    \n",
    "            print(\"=> \"+method+\" | \"+filename +' | '+str(t__)+\" done\")\n",
    "        \n",
    "print(\"All Done!\")\n",
    "print(\"=================================Not Saved List===============================\")\n",
    "for i in notsaved:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
